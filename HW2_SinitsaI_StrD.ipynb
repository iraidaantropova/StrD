{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxJRko7SkpU5WmlaNlTscR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iraidaantropova/StrD/blob/main/HW2_SinitsaI_StrD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP0Mh8Jf9r7a",
        "outputId": "e977795e-8fcb-42ad-a390-ae5769e886ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425344 sha256=296e505834b101b366d84f74d51acad8d077e9dae5ba5aa8d1db115d96ff2335\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sSOL https://dlcdn.apache.org/kafka/3.5.0/kafka_2.13-3.5.0.tgz\n",
        "\n",
        "!tar -xzf kafka_2.13-3.5.0.tgz"
      ],
      "metadata": {
        "id": "_jq4gZZO-PNa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.13-3.5.0/bin/zookeeper-server-start.sh -daemon ./kafka_2.13-3.5.0/config/zookeeper.properties\n",
        "!./kafka_2.13-3.5.0/bin/kafka-server-start.sh -daemon ./kafka_2.13-3.5.0/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ilIY2WZ-XP_",
        "outputId": "efdaf901-cf3b-449a-8e6a-1c87c5744c18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 10 secs until kafka and zookeeper services are up and running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef | grep kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9aWWPn--1PQ",
        "outputId": "f62fb376-8e81-4637-bf2b-f6dc11cbd8b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        1617       1  2 02:59 ?        00:00:02 java -Xmx512M -Xms512M -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.13-3.5.0/bin/../logs/zookeeper-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.13-3.5.0/bin/../logs -Dlog4j.configuration=file:./kafka_2.13-3.5.0/bin/../config/log4j.properties -cp /content/kafka_2.13-3.5.0/bin/../libs/activation-1.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/audience-annotations-0.13.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-basic-auth-extension-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-json-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-client-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-runtime-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-transforms-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-core-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-databind-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-dataformat-csv-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-datatype-jdk8-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-base-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-json-provider-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-jaxb-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-scala_2.13-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/javassist-3.29.2-GA.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.activation-api-1.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.annotation-api-1.3.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jaxb-api-2.3.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-client-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-common-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-hk2-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-server-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-client-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-continuation-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-http-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-io-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-security-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-server-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlet-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlets-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-ajax-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jline-3.22.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/jose4j-0.9.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-clients-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-group-coordinator-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-log4j-appender-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-metadata-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-raft-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-server-common-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-shell-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-examples-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-scala_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-test-utils-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/lz4-java-1.8.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/maven-artifact-3.8.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-buffer-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-codec-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-handler-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-resolver-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-classes-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-unix-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/paranamer-2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/plexus-utils-3.3.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.13-3.5.0/bin/../libs/reload4j-1.2.25.jar:/content/kafka_2.13-3.5.0/bin/../libs/rocksdbjni-7.1.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-library-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-reflect-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-api-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/snappy-java-1.1.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/swagger-annotations-2.2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/trogdor-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-jute-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zstd-jni-1.5.5-1.jar org.apache.zookeeper.server.quorum.QuorumPeerMain ./kafka_2.13-3.5.0/config/zookeeper.properties\n",
            "root        1980       1  6 02:59 ?        00:00:08 java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.13-3.5.0/bin/../logs/kafkaServer-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.13-3.5.0/bin/../logs -Dlog4j.configuration=file:./kafka_2.13-3.5.0/bin/../config/log4j.properties -cp /content/kafka_2.13-3.5.0/bin/../libs/activation-1.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/audience-annotations-0.13.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-basic-auth-extension-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-json-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-mirror-client-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-runtime-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/connect-transforms-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-core-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-databind-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-dataformat-csv-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-datatype-jdk8-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-base-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-jaxrs-json-provider-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-jaxb-annotations-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jackson-module-scala_2.13-2.13.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.activation-api-1.2.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.13-3.5.0/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/javassist-3.29.2-GA.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.activation-api-1.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.annotation-api-1.3.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jaxb-api-2.3.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-client-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-common-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-hk2-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jersey-server-2.39.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-client-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-continuation-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-http-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-io-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-security-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-server-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlet-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-servlets-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jetty-util-ajax-9.4.51.v20230217.jar:/content/kafka_2.13-3.5.0/bin/../libs/jline-3.22.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/jose4j-0.9.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-clients-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-group-coordinator-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-log4j-appender-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-metadata-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-raft-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-server-common-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-shell-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-storage-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-examples-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-scala_2.13-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-streams-test-utils-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/kafka-tools-api-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/lz4-java-1.8.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/maven-artifact-3.8.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-buffer-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-codec-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-handler-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-resolver-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-classes-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-epoll-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/netty-transport-native-unix-common-4.1.92.Final.jar:/content/kafka_2.13-3.5.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.13-3.5.0/bin/../libs/paranamer-2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/plexus-utils-3.3.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.13-3.5.0/bin/../libs/reload4j-1.2.25.jar:/content/kafka_2.13-3.5.0/bin/../libs/rocksdbjni-7.1.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-collection-compat_2.13-2.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-java8-compat_2.13-1.0.2.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-library-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-logging_2.13-3.9.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/scala-reflect-2.13.10.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-api-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/slf4j-reload4j-1.7.36.jar:/content/kafka_2.13-3.5.0/bin/../libs/snappy-java-1.1.10.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/swagger-annotations-2.2.8.jar:/content/kafka_2.13-3.5.0/bin/../libs/trogdor-3.5.0.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zookeeper-jute-3.6.4.jar:/content/kafka_2.13-3.5.0/bin/../libs/zstd-jni-1.5.5-1.jar kafka.Kafka ./kafka_2.13-3.5.0/config/server.properties\n",
            "root        2553     685  0 03:01 ?        00:00:00 /bin/bash -c ps -ef | grep kafka\n",
            "root        2555    2553  0 03:01 ?        00:00:00 grep kafka\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#создаем топик( таблица в кафке с параметрами партиционирования, репликации и retention time) с параметрами: partitions=2, replication-factor=1\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty-ezxWF-4Va",
        "outputId": "b0ea836f-d130-47ac-e8c1-5e9c88f675f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create, delete, describe, or change a topic.\n",
            "Option                                   Description                            \n",
            "------                                   -----------                            \n",
            "--alter                                  Alter the number of partitions and     \n",
            "                                           replica assignment. Update the       \n",
            "                                           configuration of an existing topic   \n",
            "                                           via --alter is no longer supported   \n",
            "                                           here (the kafka-configs CLI supports \n",
            "                                           altering topic configs with a --     \n",
            "                                           bootstrap-server option).            \n",
            "--at-min-isr-partitions                  if set when describing topics, only    \n",
            "                                           show partitions whose isr count is   \n",
            "                                           equal to the configured minimum.     \n",
            "--bootstrap-server <String: server to    REQUIRED: The Kafka server to connect  \n",
            "  connect to>                              to.                                  \n",
            "--command-config <String: command        Property file containing configs to be \n",
            "  config property file>                    passed to Admin Client. This is used \n",
            "                                           only with --bootstrap-server option  \n",
            "                                           for describing and altering broker   \n",
            "                                           configs.                             \n",
            "--config <String: name=value>            A topic configuration override for the \n",
            "                                           topic being created or altered. The  \n",
            "                                           following is a list of valid         \n",
            "                                           configurations:                      \n",
            "                                         \tcleanup.policy                        \n",
            "                                         \tcompression.type                      \n",
            "                                         \tdelete.retention.ms                   \n",
            "                                         \tfile.delete.delay.ms                  \n",
            "                                         \tflush.messages                        \n",
            "                                         \tflush.ms                              \n",
            "                                         \tfollower.replication.throttled.       \n",
            "                                           replicas                             \n",
            "                                         \tindex.interval.bytes                  \n",
            "                                         \tleader.replication.throttled.replicas \n",
            "                                         \tlocal.retention.bytes                 \n",
            "                                         \tlocal.retention.ms                    \n",
            "                                         \tmax.compaction.lag.ms                 \n",
            "                                         \tmax.message.bytes                     \n",
            "                                         \tmessage.downconversion.enable         \n",
            "                                         \tmessage.format.version                \n",
            "                                         \tmessage.timestamp.difference.max.ms   \n",
            "                                         \tmessage.timestamp.type                \n",
            "                                         \tmin.cleanable.dirty.ratio             \n",
            "                                         \tmin.compaction.lag.ms                 \n",
            "                                         \tmin.insync.replicas                   \n",
            "                                         \tpreallocate                           \n",
            "                                         \tremote.storage.enable                 \n",
            "                                         \tretention.bytes                       \n",
            "                                         \tretention.ms                          \n",
            "                                         \tsegment.bytes                         \n",
            "                                         \tsegment.index.bytes                   \n",
            "                                         \tsegment.jitter.ms                     \n",
            "                                         \tsegment.ms                            \n",
            "                                         \tunclean.leader.election.enable        \n",
            "                                         See the Kafka documentation for full   \n",
            "                                           details on the topic configs. It is  \n",
            "                                           supported only in combination with --\n",
            "                                           create if --bootstrap-server option  \n",
            "                                           is used (the kafka-configs CLI       \n",
            "                                           supports altering topic configs with \n",
            "                                           a --bootstrap-server option).        \n",
            "--create                                 Create a new topic.                    \n",
            "--delete                                 Delete a topic                         \n",
            "--delete-config <String: name>           A topic configuration override to be   \n",
            "                                           removed for an existing topic (see   \n",
            "                                           the list of configurations under the \n",
            "                                           --config option). Not supported with \n",
            "                                           the --bootstrap-server option.       \n",
            "--describe                               List details for the given topics.     \n",
            "--exclude-internal                       exclude internal topics when running   \n",
            "                                           list or describe command. The        \n",
            "                                           internal topics will be listed by    \n",
            "                                           default                              \n",
            "--help                                   Print usage information.               \n",
            "--if-exists                              if set when altering or deleting or    \n",
            "                                           describing topics, the action will   \n",
            "                                           only execute if the topic exists.    \n",
            "--if-not-exists                          if set when creating topics, the       \n",
            "                                           action will only execute if the      \n",
            "                                           topic does not already exist.        \n",
            "--list                                   List all available topics.             \n",
            "--partitions <Integer: # of partitions>  The number of partitions for the topic \n",
            "                                           being created or altered (WARNING:   \n",
            "                                           If partitions are increased for a    \n",
            "                                           topic that has a key, the partition  \n",
            "                                           logic or ordering of the messages    \n",
            "                                           will be affected). If not supplied   \n",
            "                                           for create, defaults to the cluster  \n",
            "                                           default.                             \n",
            "--replica-assignment <String:            A list of manual partition-to-broker   \n",
            "  broker_id_for_part1_replica1 :           assignments for the topic being      \n",
            "  broker_id_for_part1_replica2 ,           created or altered.                  \n",
            "  broker_id_for_part2_replica1 :                                                \n",
            "  broker_id_for_part2_replica2 , ...>                                           \n",
            "--replication-factor <Integer:           The replication factor for each        \n",
            "  replication factor>                      partition in the topic being         \n",
            "                                           created. If not supplied, defaults   \n",
            "                                           to the cluster default.              \n",
            "--topic <String: topic>                  The topic to create, alter, describe   \n",
            "                                           or delete. It also accepts a regular \n",
            "                                           expression, except for --create      \n",
            "                                           option. Put topic name in double     \n",
            "                                           quotes and use the '\\' prefix to     \n",
            "                                           escape regular expression symbols; e.\n",
            "                                           g. \"test\\.topic\".                    \n",
            "--topic-id <String: topic-id>            The topic-id to describe.This is used  \n",
            "                                           only with --bootstrap-server option  \n",
            "                                           for describing topics.               \n",
            "--topics-with-overrides                  if set when describing topics, only    \n",
            "                                           show topics that have overridden     \n",
            "                                           configs                              \n",
            "--unavailable-partitions                 if set when describing topics, only    \n",
            "                                           show partitions whose leader is not  \n",
            "                                           available                            \n",
            "--under-min-isr-partitions               if set when describing topics, only    \n",
            "                                           show partitions whose isr count is   \n",
            "                                           less than the configured minimum.    \n",
            "--under-replicated-partitions            if set when describing topics, only    \n",
            "                                           show under replicated partitions     \n",
            "--version                                Display Kafka version.                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем топик\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 2 --topic testtopic --config retention.ms=-1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftXLX7Sd_QNp",
        "outputId": "6aab8e4d-71a8-40d4-e133-46efab25f30d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic testtopic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяю наличие топика\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh  --list --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGoLPwS9_hCB",
        "outputId": "b61c8cba-2148-4cd7-f466-9737f8e4b106"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testtopic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#проверяю\n",
        "\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic testtopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCSTJL1I_4dC",
        "outputId": "9a266117-f84e-4675-d230-f5df4ceb83a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: testtopic\tTopicId: SJl8b1eDSb6SCP3_lBQNxQ\tPartitionCount: 2\tReplicationFactor: 1\tConfigs: retention.ms=-1\n",
            "\tTopic: testtopic\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n",
            "\tTopic: testtopic\tPartition: 1\tLeader: 0\tReplicas: 0\tIsr: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#создаю продюсера (сервер, который поставляет сообщения в топик), отправляю несколько сообщений в топик\n",
        "!./kafka_2.13-3.5.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testtopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHgRY38oADVI",
        "outputId": "5b293b23-1597-4f0d-923b-aac0ffdc47bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1\n",
            ">2\n",
            ">3\n",
            ">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавляю в топик новые данные\n",
        "!./kafka_2.13-3.5.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testtopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgQ7C5TyEyN_",
        "outputId": "77e86045-0243-441d-edf1-8c345756d59d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">7\n",
            ">8\n",
            ">9\n",
            ">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаю записанный топик\n",
        "!./kafka_2.13-3.5.0/bin/kafka-console-consumer.sh --topic testtopic --from-beginning --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NIM6wkRE-52",
        "outputId": "600c6f10-866c-4ce8-87c5-c1740bf0ee5e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "8\n",
            "9\n",
            "1\n",
            "2\n",
            "3\n",
            "Processed a total of 6 messages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Удаляю топик\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --delete --topic testtopic"
      ],
      "metadata": {
        "id": "y5dFO643FQMv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh  --list --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQhCUqB3FV88",
        "outputId": "e56f1f79-bcd7-42a1-c3bc-038a264e3476"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__consumer_offsets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаю топик со временем жизни 1 минута\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 2 --topic testtopic --config retention.ms=60000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMSSRN0SFawE",
        "outputId": "2bbcf802-d060-4662-abd0-b6745d7baed7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic testtopic.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка\n",
        "\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh  --list --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNbtbKPkFgFE",
        "outputId": "3e0027b5-28b8-4a7a-9667-aaed02e0020a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__consumer_offsets\n",
            "testtopic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Описание\n",
        "!./kafka_2.13-3.5.0/bin/kafka-topics.sh --describe --bootstrap-server 127.0.0.1:9092 --topic testtopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdCzEgZeG02d",
        "outputId": "0f41c16d-944c-4e53-f831-927ad029d5df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: testtopic\tTopicId: HB0v0TPPS-SonvC48Ia6jA\tPartitionCount: 2\tReplicationFactor: 1\tConfigs: retention.ms=60000\n",
            "\tTopic: testtopic\tPartition: 0\tLeader: 0\tReplicas: 0\tIsr: 0\n",
            "\tTopic: testtopic\tPartition: 1\tLeader: 0\tReplicas: 0\tIsr: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаю продюсера и отправляю несколько сообщений в топик\n",
        "!./kafka_2.13-3.5.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testtopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKkQhri0G46H",
        "outputId": "85ed29ca-0687-4548-bacd-c7961539d862"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">5\n",
            ">6\n",
            ">7\n",
            ">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Дописываю\n",
        "!./kafka_2.13-3.5.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testtopic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9_1d8-vJqTH",
        "outputId": "d5d5d4b5-7b00-4cf3-8a82-e935e82505a5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">12\n",
            ">13\n",
            ">14\n",
            ">"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаю консьюмера и читаю отправленные сообщения\n",
        "!./kafka_2.13-3.5.0/bin/kafka-console-consumer.sh --topic testtopic --from-beginning --bootstrap-server localhost:9092"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygXThsdTJyEM",
        "outputId": "63de1c32-1772-4690-8712-8d433af97164"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "13\n",
            "14\n",
            "Processed a total of 3 messages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spark-submit --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSKRKyPgKUM6",
        "outputId": "57265543-5eff-485f-98cb-21403e863924"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.5.0\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.18, OpenJDK 64-Bit Server VM, 11.0.20.1\n",
            "Branch HEAD\n",
            "Compiled by user ubuntu on 2023-09-09T01:53:20Z\n",
            "Revision ce5ddad990373636e94071e7cef2f31021add07b\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.kafka:kafka-clients:3.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjzL43Q1KYVZ",
        "outputId": "687e0fa8-0b39-4ffa-e5f7-0474de526fce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] on linux\n",
            "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
            ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
            "Ivy Default Cache set to: /root/.ivy2/cache\n",
            "The jars for the packages stored in: /root/.ivy2/jars\n",
            "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
            "org.apache.kafka#kafka-clients added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7921219f-a1b0-40c9-85cc-c5837bb7c3e6;1.0\n",
            "\tconfs: [default]\n",
            "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central\n",
            "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
            "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
            "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
            "\tfound commons-logging#commons-logging;1.1.3 in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
            "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
            "\tfound org.apache.kafka#kafka-clients;3.5.0 in central\n",
            "\tfound com.github.luben#zstd-jni;1.5.5-1 in central\n",
            "\tfound org.lz4#lz4-java;1.8.0 in central\n",
            "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0!spark-sql-kafka-0-10_2.12.jar (63ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.5.0/kafka-clients-3.5.0.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.5.0!kafka-clients.jar (209ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0!spark-token-provider-kafka-0-10_2.12.jar (58ms)\n",
            "downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...\n",
            "\t[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (69ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (60ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (587ms)\n",
            "downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...\n",
            "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (286ms)\n",
            "downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...\n",
            "\t[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (76ms)\n",
            "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...\n",
            "\t[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (33ms)\n",
            "downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...\n",
            "\t[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (38ms)\n",
            "downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.5.5-1/zstd-jni-1.5.5-1.jar ...\n",
            "\t[SUCCESSFUL ] com.github.luben#zstd-jni;1.5.5-1!zstd-jni.jar (114ms)\n",
            "downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...\n",
            "\t[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (48ms)\n",
            ":: resolution report :: resolve 5310ms :: artifacts dl 1676ms\n",
            "\t:: modules in use:\n",
            "\tcom.github.luben#zstd-jni;1.5.5-1 from central in [default]\n",
            "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
            "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
            "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
            "\torg.apache.kafka#kafka-clients;3.5.0 from central in [default]\n",
            "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]\n",
            "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]\n",
            "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
            "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
            "\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]\n",
            "\t:: evicted modules:\n",
            "\torg.apache.kafka#kafka-clients;3.4.1 by [org.apache.kafka#kafka-clients;3.5.0] in [default]\n",
            "\torg.xerial.snappy#snappy-java;1.1.10.0 by [org.xerial.snappy#snappy-java;1.1.10.3] in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.36 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |   15  |   12  |   12  |   3   ||   12  |   12  |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-7921219f-a1b0-40c9-85cc-c5837bb7c3e6\n",
            "\tconfs: [default]\n",
            "\t12 artifacts copied, 0 already retrieved (62800kB/407ms)\n",
            "23/10/13 03:52:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.5.0\n",
            "      /_/\n",
            "\n",
            "Using Python version 3.10.12 (main, Jun 11 2023 05:26:28)\n",
            "Spark context Web UI available at http://fa6bcccb0a73:4040\n",
            "Spark context available as 'sc' (master = local[*], app id = local-1697169131914).\n",
            "SparkSession available as 'spark'.\n",
            ">>> \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/context.py\", line 381, in signal_handler\n",
            "    self.cancelAllJobs()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/context.py\", line 2446, in cancelAllJobs\n",
            "    self._jsc.sc().cancelAllJobs()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1314, in __call__\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1277, in _build_args\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pyspark/context.py\", line 382, in signal_handler\n",
            "    raise KeyboardInterrupt()\n",
            "KeyboardInterrupt\n",
            ">>> ^C\n"
          ]
        }
      ]
    }
  ]
}